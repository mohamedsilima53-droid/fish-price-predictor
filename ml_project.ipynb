{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "id": "md0",
      "metadata": {},
      "source": "# \ud83d\udc1f Tanzania Fish Price Prediction\n## Machine Learning Project\n**Objective:** Predict fish prices (in TZS) based on fish characteristics, market conditions, and region using Linear Regression and Decision Tree models."
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# ============================================================\n# 1. IMPORT LIBRARIES\n# ============================================================\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport joblib\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint(\"\u2705 Libraries imported successfully!\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "md0",
      "metadata": {},
      "source": "## 2. Load & Explore the Dataset"
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# ============================================================\n# 2. LOAD DATASET\n# ============================================================\ndf = pd.read_csv('tanzania_fish_prices.csv')\n\nprint(\"\ud83d\udcca Dataset Shape:\", df.shape)\nprint(\"\\n\ud83d\udccb First 5 rows:\")\ndf.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "print(\"\ud83d\udccc Dataset Info:\")\ndf.info()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "print(\"\ud83d\udcc8 Statistical Summary:\")\ndf.describe()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "print(\"\ud83d\udd0d Missing Values:\")\nprint(df.isnull().sum())\nprint(\"\\n\u2705 No missing values!\" if df.isnull().sum().sum() == 0 else \"\u26a0\ufe0f Missing values found!\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "md0",
      "metadata": {},
      "source": "## 3. Exploratory Data Analysis (EDA)"
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# ============================================================\n# 3. EXPLORATORY DATA ANALYSIS\n# ============================================================\n\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\nfig.suptitle('Tanzania Fish Price Dataset \u2014 Exploratory Data Analysis', fontsize=15, fontweight='bold')\n\n# Price distribution\naxes[0,0].hist(df['price_tzs'], bins=30, color='#2196F3', edgecolor='white', alpha=0.85)\naxes[0,0].set_title('Distribution of Fish Prices (TZS)')\naxes[0,0].set_xlabel('Price (TZS)')\naxes[0,0].set_ylabel('Frequency')\n\n# Average price by species\navg_species = df.groupby('species')['price_tzs'].mean().sort_values(ascending=False)\naxes[0,1].bar(avg_species.index, avg_species.values, color=['#4CAF50','#2196F3','#FF9800','#E91E63','#9C27B0'])\naxes[0,1].set_title('Average Price by Fish Species')\naxes[0,1].set_xlabel('Species')\naxes[0,1].set_ylabel('Avg Price (TZS)')\naxes[0,1].tick_params(axis='x', rotation=15)\n\n# Average price by season\navg_season = df.groupby('season')['price_tzs'].mean()\naxes[0,2].bar(avg_season.index, avg_season.values, color=['#03A9F4','#FF5722'])\naxes[0,2].set_title('Average Price by Season')\naxes[0,2].set_xlabel('Season')\naxes[0,2].set_ylabel('Avg Price (TZS)')\n\n# Price by market type\ndf.boxplot(column='price_tzs', by='market_type', ax=axes[1,0], \n           boxprops=dict(color='#2196F3'), medianprops=dict(color='red'))\naxes[1,0].set_title('Price Distribution by Market Type')\naxes[1,0].set_xlabel('Market Type')\naxes[1,0].set_ylabel('Price (TZS)')\nplt.sca(axes[1,0])\nplt.xticks(rotation=10)\n\n# Price vs Weight\naxes[1,1].scatter(df['weight_kg'], df['price_tzs'], alpha=0.4, color='#9C27B0', s=20)\naxes[1,1].set_title('Price vs Fish Weight')\naxes[1,1].set_xlabel('Weight (kg)')\naxes[1,1].set_ylabel('Price (TZS)')\n\n# Price vs Freshness\naxes[1,2].scatter(df['freshness_days'], df['price_tzs'], alpha=0.4, color='#FF5722', s=20)\naxes[1,2].set_title('Price vs Freshness (Days Old)')\naxes[1,2].set_xlabel('Days Since Catch')\naxes[1,2].set_ylabel('Price (TZS)')\n\nplt.tight_layout()\nplt.savefig('eda_plots.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 EDA plots saved!\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# Correlation heatmap (numeric features)\nfig, ax = plt.subplots(figsize=(8, 6))\nnumeric_df = df[['weight_kg', 'freshness_days', 'distance_to_market_km', 'quantity_kg', 'price_tzs']]\ncorr = numeric_df.corr()\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', ax=ax, \n            linewidths=0.5, square=True, cbar_kws={'shrink': 0.8})\nax.set_title('Correlation Matrix of Numeric Features', fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig('correlation_heatmap.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Correlation heatmap saved!\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "md0",
      "metadata": {},
      "source": "## 4. Data Preprocessing"
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# ============================================================\n# 4. DATA PREPROCESSING\n# ============================================================\n\ndf_processed = df.copy()\n\n# Encode categorical variables\nle = LabelEncoder()\ncat_cols = ['species', 'region', 'season', 'market_type', 'quality_grade']\n\nencoders = {}\nfor col in cat_cols:\n    encoders[col] = LabelEncoder()\n    df_processed[col] = encoders[col].fit_transform(df_processed[col])\n    print(f\"\u2705 Encoded '{col}': {dict(zip(encoders[col].classes_, encoders[col].transform(encoders[col].classes_)))}\")\n\nprint(\"\\n\ud83d\udccb Processed dataset (first 5 rows):\")\ndf_processed.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# Define features and target\nX = df_processed.drop('price_tzs', axis=1)\ny = df_processed['price_tzs']\n\nprint(\"Features (X):\", list(X.columns))\nprint(\"Target (y): price_tzs\")\nprint(f\"\\nDataset size: {X.shape[0]} rows \u00d7 {X.shape[1]} features\")\n\n# Split into train and test sets (80/20)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(f\"\\n\u2705 Training set: {X_train.shape[0]} samples\")\nprint(f\"\u2705 Testing set:  {X_test.shape[0]} samples\")\n\n# Feature scaling (for Linear Regression)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\nprint(\"\\n\u2705 Features scaled successfully!\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "md0",
      "metadata": {},
      "source": "## 5. Model Training & Evaluation"
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# ============================================================\n# 5A. LINEAR REGRESSION MODEL\n# ============================================================\n\nlr_model = LinearRegression()\nlr_model.fit(X_train_scaled, y_train)\n\n# Predictions\ny_pred_lr = lr_model.predict(X_test_scaled)\n\n# Metrics\nlr_mae  = mean_absolute_error(y_test, y_pred_lr)\nlr_mse  = mean_squared_error(y_test, y_pred_lr)\nlr_rmse = np.sqrt(lr_mse)\nlr_r2   = r2_score(y_test, y_pred_lr)\nlr_cv   = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n\nprint(\"=\" * 45)\nprint(\"  \ud83d\udcca LINEAR REGRESSION RESULTS\")\nprint(\"=\" * 45)\nprint(f\"  MAE  : {lr_mae:>12,.2f} TZS\")\nprint(f\"  RMSE : {lr_rmse:>12,.2f} TZS\")\nprint(f\"  R\u00b2   : {lr_r2:>12.4f}\")\nprint(f\"  CV R\u00b2: {lr_cv:>12.4f}\")\nprint(\"=\" * 45)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# ============================================================\n# 5B. DECISION TREE MODEL\n# ============================================================\n\ndt_model = DecisionTreeRegressor(max_depth=6, random_state=42)\ndt_model.fit(X_train, y_train)\n\n# Predictions\ny_pred_dt = dt_model.predict(X_test)\n\n# Metrics\ndt_mae  = mean_absolute_error(y_test, y_pred_dt)\ndt_mse  = mean_squared_error(y_test, y_pred_dt)\ndt_rmse = np.sqrt(dt_mse)\ndt_r2   = r2_score(y_test, y_pred_dt)\ndt_cv   = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='r2').mean()\n\nprint(\"=\" * 45)\nprint(\"  \ud83c\udf33 DECISION TREE RESULTS\")\nprint(\"=\" * 45)\nprint(f\"  MAE  : {dt_mae:>12,.2f} TZS\")\nprint(f\"  RMSE : {dt_rmse:>12,.2f} TZS\")\nprint(f\"  R\u00b2   : {dt_r2:>12.4f}\")\nprint(f\"  CV R\u00b2: {dt_cv:>12.4f}\")\nprint(\"=\" * 45)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "md0",
      "metadata": {},
      "source": "## 6. Model Comparison & Visualization"
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# ============================================================\n# 6. MODEL COMPARISON VISUALIZATIONS\n# ============================================================\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 11))\nfig.suptitle('Model Evaluation: Linear Regression vs Decision Tree', fontsize=15, fontweight='bold')\n\n# --- Plot 1: Metrics Comparison ---\nmetrics = ['MAE', 'RMSE', 'R\u00b2', 'CV R\u00b2']\nlr_vals = [lr_mae, lr_rmse, lr_r2 * 10000, lr_cv * 10000]\ndt_vals = [dt_mae, dt_rmse, dt_r2 * 10000, dt_cv * 10000]\n\nx = np.arange(len(metrics))\nwidth = 0.35\nbars1 = axes[0,0].bar(x - width/2, [lr_mae, lr_rmse, lr_r2, lr_cv], width, label='Linear Regression', color='#2196F3', alpha=0.85)\nbars2 = axes[0,0].bar(x + width/2, [dt_mae, dt_rmse, dt_r2, dt_cv], width, label='Decision Tree', color='#4CAF50', alpha=0.85)\naxes[0,0].set_title('Metrics Comparison (MAE, RMSE normalized)')\naxes[0,0].set_xticks(x)\naxes[0,0].set_xticklabels(metrics)\naxes[0,0].legend()\naxes[0,0].set_ylabel('Value')\n\n# --- Plot 2: Actual vs Predicted (LR) ---\naxes[0,1].scatter(y_test, y_pred_lr, alpha=0.5, color='#2196F3', s=25, label='Predictions')\nlim = [min(y_test.min(), y_pred_lr.min()), max(y_test.max(), y_pred_lr.max())]\naxes[0,1].plot(lim, lim, 'r--', lw=2, label='Perfect Fit')\naxes[0,1].set_title(f'Linear Regression: Actual vs Predicted\\nR\u00b2 = {lr_r2:.4f}')\naxes[0,1].set_xlabel('Actual Price (TZS)')\naxes[0,1].set_ylabel('Predicted Price (TZS)')\naxes[0,1].legend()\n\n# --- Plot 3: Actual vs Predicted (DT) ---\naxes[1,0].scatter(y_test, y_pred_dt, alpha=0.5, color='#4CAF50', s=25, label='Predictions')\naxes[1,0].plot(lim, lim, 'r--', lw=2, label='Perfect Fit')\naxes[1,0].set_title(f'Decision Tree: Actual vs Predicted\\nR\u00b2 = {dt_r2:.4f}')\naxes[1,0].set_xlabel('Actual Price (TZS)')\naxes[1,0].set_ylabel('Predicted Price (TZS)')\naxes[1,0].legend()\n\n# --- Plot 4: Residuals ---\nlr_resid = y_test - y_pred_lr\ndt_resid = y_test - y_pred_dt\naxes[1,1].hist(lr_resid, bins=25, alpha=0.6, color='#2196F3', label='LR Residuals')\naxes[1,1].hist(dt_resid, bins=25, alpha=0.6, color='#4CAF50', label='DT Residuals')\naxes[1,1].axvline(0, color='red', linestyle='--')\naxes[1,1].set_title('Residuals Distribution')\naxes[1,1].set_xlabel('Residual (TZS)')\naxes[1,1].legend()\n\nplt.tight_layout()\nplt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Model comparison plots saved!\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# Feature importance (Decision Tree)\nfeat_imp = pd.Series(dt_model.feature_importances_, index=X.columns).sort_values(ascending=True)\n\nfig, ax = plt.subplots(figsize=(8, 5))\ncolors = ['#FF9800' if v == feat_imp.max() else '#2196F3' for v in feat_imp.values]\nfeat_imp.plot(kind='barh', ax=ax, color=colors)\nax.set_title('Feature Importance \u2014 Decision Tree Model', fontsize=13, fontweight='bold')\nax.set_xlabel('Importance Score')\nplt.tight_layout()\nplt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\u2705 Feature importance plot saved!\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "md0",
      "metadata": {},
      "source": "## 7. Select Best Model & Save"
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# ============================================================\n# 7. SELECT BEST MODEL & SAVE\n# ============================================================\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\"       \ud83c\udfc6 MODEL SELECTION SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"{'Metric':<15} {'Linear Reg':>15} {'Decision Tree':>15}\")\nprint(\"-\" * 50)\nprint(f\"{'MAE (TZS)':<15} {lr_mae:>15,.2f} {dt_mae:>15,.2f}\")\nprint(f\"{'RMSE (TZS)':<15} {lr_rmse:>15,.2f} {dt_rmse:>15,.2f}\")\nprint(f\"{'R\u00b2 Score':<15} {lr_r2:>15.4f} {dt_r2:>15.4f}\")\nprint(f\"{'CV R\u00b2 Score':<15} {lr_cv:>15.4f} {dt_cv:>15.4f}\")\nprint(\"=\" * 50)\n\nbest_model_name = \"Decision Tree\" if dt_r2 > lr_r2 else \"Linear Regression\"\nbest_model = dt_model if dt_r2 > lr_r2 else lr_model\nbest_r2 = max(dt_r2, lr_r2)\n\nprint(f\"\\n\u2705 Best Model: {best_model_name} (R\u00b2 = {best_r2:.4f})\")\n\n# Save the best model\njoblib.dump(best_model, 'model.pkl')\njoblib.dump(scaler, 'scaler.pkl')\njoblib.dump(encoders, 'encoders.pkl')\nprint(\"\\n\ud83d\udcbe Saved: model.pkl, scaler.pkl, encoders.pkl\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c0",
      "metadata": {},
      "source": "# Verify saved model works\nloaded_model = joblib.load('model.pkl')\ntest_pred = loaded_model.predict(X_test[:5])\nprint(\"\u2705 Model loaded & verified!\")\nprint(\"\\nSample predictions (TZS):\")\nfor i, (pred, actual) in enumerate(zip(test_pred, y_test.values[:5])):\n    print(f\"  Sample {i+1}: Predicted = {pred:>10,.2f} | Actual = {actual:>10,.2f}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "md0",
      "metadata": {},
      "source": "## \u2705 Summary\n\n| Item | Details |\n|------|---------|\n| **Dataset** | 500 records of Tanzania fish prices |\n| **Features** | Species, Region, Season, Market Type, Quality, Weight, Freshness, Distance, Quantity |\n| **Target** | Fish Price (TZS) |\n| **Models** | Linear Regression & Decision Tree |\n| **Best Model** | Decision Tree (higher R\u00b2) |\n| **Saved Files** | `model.pkl`, `scaler.pkl`, `encoders.pkl` |"
    }
  ]
}